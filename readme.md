# Finetuning Llama models

This repository contains scripts used to finetune Llama models and outcomes of finetuning.

For inference, a Python environment should be created according to the requirements from the `requirements.txt` file.

For finetuning, the library `llama-recipes` is used, which was installed from source.

To use it in the same way, it is necessary to clone `llama-recipes` into a separate directory, then run `pip install -e .` in the root of that directory, after activating the correct virtual environment.

All the scripts should be run from the root directory.